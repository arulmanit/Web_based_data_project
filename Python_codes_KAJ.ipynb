{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial temporal risk assessment to aid in planning for malaria elimination in Senegal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (Submission by Kristin, Arul, Jacqueline )                                                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python code used in our analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing shape file and Geo-spatial visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "# importing necessary libraries\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona\n",
    "# opening the shape file\n",
    "senegal = fiona.open(\"senegal_arr_2014_wgs.shp\")\n",
    "senegal = gpd.read_file(\"senegal_arr_2014_wgs.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for the information on the data\n",
    "senegal.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senegal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senegal.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(senegal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(senegal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geo-spatial mapping of senegal region with color framework as jet\n",
    "senegal.plot(cmap = 'jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geo-spatial mapping of senegal region with specific to region\n",
    "senegal.plot(cmap = 'jet', column = 'REG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geo-spatial mapping of senegal region with modified size\n",
    "senegal.plot(cmap = 'jet', column = 'REG', figsize  = (10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senegal.geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Mapping individual trajectories of 1000 individuals to determine travel patterns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import skmob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file that will be the trajectory data frame (tdf) - JANUARY\n",
    "tdf_01 = skmob.TrajDataFrame.from_file('/Users/thewooz/Documents/DATA_WEBBASED/SET3/SET3_M01.CSV.gz',header=None)\n",
    "\n",
    "# read the file that will be the trajectory data frame (tdf) - OCTOBER\n",
    "tdf_10 = skmob.TrajDataFrame.from_file('/Users/thewooz/Documents/DATA_WEBBASED/SET3/SET3_M10.CSV.gz',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_01.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "newcols = {\n",
    "    0: 'uid', \n",
    "    1: 'datetime', \n",
    "    2: 'arr_id'\n",
    "}\n",
    "tdf_01.rename(columns=newcols, inplace=True)\n",
    "tdf_10.rename(columns=newcols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with the average latitude and longitude for each arrondissement\n",
    "\n",
    "# read in the lat and long data\n",
    "coord = pd.read_csv('/Users/thewooz/Documents/DATA_WEBBASED/ContextData/SITE_ARR_LONLAT.CSV', index_col=0)\n",
    "\n",
    "# get the average lat and long per neighborhood\n",
    "coord_mean = coord.groupby(['arr_id']).mean()\n",
    "\n",
    "# merge tdf file with coordinates\n",
    "tdf_01 = pd.merge(tdf_01, coord_mean, on='arr_id', how ='left')\n",
    "tdf_10 = pd.merge(tdf_10, coord_mean, on='arr_id', how ='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "newcols = {\n",
    "    'lon': 'lng'\n",
    "}\n",
    "tdf_01.rename(columns=newcols, inplace=True)\n",
    "tdf_10.rename(columns=newcols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a trajectory map for 1000 people\n",
    "map_f_01 = tdf_01.plot_trajectory(max_users=1000, hex_color='#000000',start_end_markers=False,opacity=0.25,weight=1)\n",
    "map_f_10 = tdf_10.plot_trajectory(max_users=1000, hex_color='#000000',start_end_markers=False,opacity=0.25,weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_f_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_f_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Creating a dataframe needed to use \"flow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pacakages\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in quarterly undup data - this data is unduplicated to one record per person, per day, per arrondisement\n",
    "q1 = pd.read_pickle('q1_coord.pkl')\n",
    "q2 = pd.read_pickle('q2_coord.pkl')\n",
    "q3 = pd.read_pickle('q3_coord.pkl')\n",
    "q4 = pd.read_pickle('q4_coord.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at data for q1\n",
    "q1.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the dataframes to just the needed data, user_id and arr_id\n",
    "q1_reduced = q1.loc[:, ['user_id','arr_id']]\n",
    "q2_reduced = q2.loc[:, ['user_id','arr_id']]\n",
    "q3_reduced = q3.loc[:, ['user_id','arr_id']]\n",
    "q4_reduced = q4.loc[:, ['user_id','arr_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the mode arrondissement for each user in each quarter\n",
    "# NOTE:  this takes way too long to process - changing to capture just the first arrondissement for each user_id\n",
    "\n",
    "#q1_modearr = q1_reduced.groupby('user_id').apply(pd.DataFrame.mode).reset_index(drop=True)\n",
    "#q2_modearr = q2_reduced.groupby('user_id').apply(pd.DataFrame.mode).reset_index(drop=True)\n",
    "#q3_modearr = q3_reduced.groupby('user_id').apply(pd.DataFrame.mode).reset_index(drop=True)\n",
    "#q4_modearr = q4_reduced.groupby('user_id').apply(pd.DataFrame.mode).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# unduplicate - one user_id per QUARTER, keeping only the first arrondisement per person\n",
    "q1_firstarr = q1_reduced.reset_index().drop_duplicates(subset=['user_id'], keep='first').set_index('index')\n",
    "q2_firstarr = q2_reduced.reset_index().drop_duplicates(subset=['user_id'], keep='first').set_index('index')\n",
    "q3_firstarr = q3_reduced.reset_index().drop_duplicates(subset=['user_id'], keep='first').set_index('index')\n",
    "q4_firstarr = q4_reduced.reset_index().drop_duplicates(subset=['user_id'], keep='first').set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_firstarr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the most populous arrondissements in order to find which ones to include in the analysis\n",
    "q1_firstarr['arr_id'].value_counts().head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group each QUARTER by the arr_id\n",
    "q1_gb = q1_firstarr.groupby('arr_id') \n",
    "q2_gb = q2_firstarr.groupby('arr_id') \n",
    "q3_gb = q3_firstarr.groupby('arr_id') \n",
    "q4_gb = q4_firstarr.groupby('arr_id') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[q1_gb.get_group(x) for x in q1_gb.groups]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unable to figure out how to loop through the data files in order to compare all arrondissements and quarters. Thefore, code below captures the number of people who moved from the most populous arrondissement (4) to the next most populous (3,7,25,2, and 6). Will manually create a dataframe that can be used in Scikit-Mobility Flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q1->q2:  4->3 \n",
    "sum(q1_gb.get_group(4)['user_id'].isin(q2_gb.get_group(3)['user_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q1->q2:  4->7 \n",
    "sum(q1_gb.get_group(4)['user_id'].isin(q2_gb.get_group(7)['user_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q1->q2:  4->25\n",
    "sum(q1_gb.get_group(4)['user_id'].isin(q2_gb.get_group(25)['user_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q1->q2:  4->2\n",
    "sum(q1_gb.get_group(4)['user_id'].isin(q2_gb.get_group(2)['user_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q1->q2:  4->6\n",
    "sum(q1_gb.get_group(4)['user_id'].isin(q2_gb.get_group(6)['user_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q2->q3:  4->3\n",
    "sum(q2_gb.get_group(4)['user_id'].isin(q3_gb.get_group(3)['user_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q2->q3:  4->7\n",
    "sum(q2_gb.get_group(4)['user_id'].isin(q3_gb.get_group(7)['user_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q2->q3:  4->25\n",
    "sum(q2_gb.get_group(4)['user_id'].isin(q3_gb.get_group(25)['user_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q2->q3:  4->2\n",
    "sum(q2_gb.get_group(4)['user_id'].isin(q3_gb.get_group(2)['user_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q2->q3:  4->6\n",
    "sum(q2_gb.get_group(4)['user_id'].isin(q3_gb.get_group(6)['user_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q3->q4:  4->3\n",
    "sum(q3_gb.get_group(4)['user_id'].isin(q4_gb.get_group(3)['user_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q3->q4:  4->7\n",
    "sum(q3_gb.get_group(4)['user_id'].isin(q4_gb.get_group(7)['user_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q3->q4:  4->25\n",
    "sum(q3_gb.get_group(4)['user_id'].isin(q4_gb.get_group(25)['user_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q3->q4:  4->2\n",
    "sum(q3_gb.get_group(4)['user_id'].isin(q4_gb.get_group(2)['user_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q3->q4:  4->6\n",
    "sum(q3_gb.get_group(4)['user_id'].isin(q4_gb.get_group(6)['user_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after getting the numbers above, calculate the total who made each journey (done manually)\n",
    "# create a dataframe from these numbers\n",
    "\n",
    "flowdf = pd.DataFrame(np.array([[4,3,6587], \n",
    "                                [4,7,1969], \n",
    "                                [4,25,320], \n",
    "                                [4,2,4957], \n",
    "                                [4,6,1378]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flowdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the new names of your columns\n",
    "newcols = {\n",
    "    0: 'origin', \n",
    "    1: 'destination', \n",
    "    2: 'flow'\n",
    "}\n",
    "flowdf.rename(columns=newcols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flowdf['origin'] = flowdf['origin'].astype(str)\n",
    "flowdf['destination'] = flowdf['destination'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flowdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flowdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flowdf.to_pickle('flow_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Combining months into quarters and merge with longitude and latitude data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in Jan - Dec pickled files\n",
    "m1 = pd.read_pickle('ds3_01_undup.pkl')\n",
    "m2 = pd.read_pickle('ds3_02_undup.pkl')\n",
    "m3 = pd.read_pickle('ds3_03_undup.pkl')\n",
    "m4 = pd.read_pickle('ds3_04_undup.pkl')\n",
    "m5 = pd.read_pickle('ds3_05_undup.pkl')\n",
    "m6 = pd.read_pickle('ds3_06_undup.pkl')\n",
    "m7 = pd.read_pickle('ds3_07_undup.pkl')\n",
    "m8 = pd.read_pickle('ds3_08_undup.pkl')\n",
    "m9 = pd.read_pickle('ds3_09_undup.pkl')\n",
    "m10 = pd.read_pickle('ds3_10_undup.pkl')\n",
    "m11 = pd.read_pickle('ds3_11_undup.pkl')\n",
    "m12 = pd.read_pickle('ds3_12_undup.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat the months to form quarters\n",
    "q1 = pd.concat([m1,m2,m3], ignore_index=True)\n",
    "q2 = pd.concat([m4,m5,m6], ignore_index=True)\n",
    "q3 = pd.concat([m7,m8,m9], ignore_index=True)\n",
    "q4 = pd.concat([m10,m11,m12], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the lat and long data\n",
    "coord = pd.read_csv('/Users/thewooz/Documents/DATA_WEBBASED/ContextData/SITE_ARR_LONLAT.CSV', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the average lat and long per neighborhood\n",
    "coord_mean = coord.groupby(['arr_id']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_coord.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_coord.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the quarter data with coordinates\n",
    "\n",
    "q1_coord.to_pickle('q1_coord.pkl')\n",
    "q2_coord.to_pickle('q2_coord.pkl')\n",
    "q3_coord.to_pickle('q3_coord.pkl')\n",
    "q4_coord.to_pickle('q4_coord.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Creating a Flow pattern using Scikit Mobility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skmob\n",
    "import geopandas as gpd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the flow dataframe\n",
    "flowdf = pd.read_pickle('/Users/thewooz/Documents/ClassNotes/WebData/SenegalProject/flow_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the shapes\n",
    "shapes = pd.read_pickle('/Users/thewooz/Documents/ClassNotes/WebData/SenegalProject/senegal.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new names of columns\n",
    "shapes.rename(columns={'ARR_ID':'tile_ID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from skmob import FlowDataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify th3e tessellation file\n",
    "tessellation = gpd.GeoDataFrame(shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = FlowDataFrame(flowdf,tessellation=tessellation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf.plot_flows(min_flow=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: A bug was reported to the package developers on November 19, 2019 but the developers have not provided a corrected release."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
